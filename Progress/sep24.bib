@article{doi:10.1080/23311916.2019.1632046,
	author = {Faiza Gul, Wan Rahiman and Syed Sahal Nazli Alhady},
	editor = {Kun Chen},
	title = {A comprehensive study for robot navigation techniques},
	journal = {Cogent Engineering},
	volume = {6},
	number = {1},
	pages = {1632046},
	year = {2019},
	publisher = {Cogent OA},
	doi = {10.1080/23311916.2019.1632046},
	
	
	URL = { 
	
	https://doi.org/10.1080/23311916.2019.1632046
	
	
	
	},
	eprint = { 
	
	https://doi.org/10.1080/23311916.2019.1632046
	
	
	
	}
	
}

@Article{rs16142512,
AUTHOR = {Qiu, Haiyang and Tang, Yijie and Wang, Hui and Wang, Lei and Xiang, Dan and Xiao, Mingming},
TITLE = {An Improved Underwater Visual SLAM through Image Enhancement and Sonar Fusion},
JOURNAL = {Remote Sensing},
VOLUME = {16},
YEAR = {2024},
NUMBER = {14},
ARTICLE-NUMBER = {2512},
URL = {https://www.mdpi.com/2072-4292/16/14/2512},
ISSN = {2072-4292},
ABSTRACT = {To enhance the performance of visual SLAM in underwater environments, this paper presents an enhanced front-end method based on visual feature enhancement. The method comprises three modules aimed at optimizing and improving the matching capability of visual features from different perspectives. Firstly, to address issues related to insufficient underwater illumination and uneven distribution of artificial light sources, a brightness-consistency recovery method is proposed. This method employs an adaptive histogram equalization algorithm to balance the brightness of images. Secondly, a method for denoising underwater suspended particulates is introduced to filter out noise from images. After image-level processing, a combined underwater acoustoâ€“optic feature-association method is proposed, which associates acoustic features from sonar with visual features, thereby providing distance information for visual features. Finally, utilizing the AFRL dataset, the improved system incorporating the proposed enhancement methods is evaluated for its performance against the OKVIS framework. The system achieves a better trajectory estimation accuracy compared to OKVIS and demonstrates robustness in underwater environments.},
DOI = {10.3390/rs16142512}
}

@ARTICLE{10373872,
	author={Putra, Oddy Virgantara and Riansyah, Moch. Iskandar and Rahmanti, Farah Zakiyah and Priyadi, Ardyono and Wulandari, Diah Puspito and Ogata, Kohichi and Yuniarno, Eko Mulyanto and Purnomo, Mauridhi Hery},
	journal={IEEE Access}, 
	title={Enhancing LiDAR-Based Object Recognition Through a Novel Denoising and Modified GDANet Framework}, 
	year={2024},
	volume={12},
	number={},
	pages={7285-7297},
	keywords={Point cloud compression;Noise reduction;Three-dimensional displays;Laser radar;Object recognition;Task analysis;Clutter;Depthwise convolution;LiDAR;human pose classification;object recognition;point cloud denoising},
	doi={10.1109/ACCESS.2023.3347033}}
